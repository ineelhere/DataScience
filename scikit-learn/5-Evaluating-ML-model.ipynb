{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a ML Model\n",
    "![](https://media.giphy.com/media/mnwc6vn9T8dag/giphy.gif)<br>\n",
    "###### Give this a read - https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "<p>There are 3 different APIs for evaluating the quality of a model&rsquo;s predictions:</p>\n",
    "<ul class=\"simple\">\n",
    "<li>\n",
    "<p><strong>Estimator score method</strong>: Estimators have a&nbsp;<code class=\"docutils literal notranslate\"><span class=\"pre\">score</span></code>&nbsp;method providing a default evaluation criterion for the problem they are designed to solve. This is not discussed on this page, but in each estimator&rsquo;s documentation.</p>\n",
    "</li>\n",
    "<li>\n",
    "<p><strong>Scoring parameter</strong>: Model-evaluation tools using&nbsp;<a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\"><span class=\"std std-ref\">cross-validation</span></a>&nbsp;(such as&nbsp;<a class=\"reference internal\" title=\"sklearn.model_selection.cross_val_score\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">model_selection.cross_val_score</span></code></a>&nbsp;and&nbsp;<a class=\"reference internal\" title=\"sklearn.model_selection.GridSearchCV\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">model_selection.GridSearchCV</span></code></a>) rely on an internal&nbsp;<em>scoring</em>&nbsp;strategy. This is discussed in the section&nbsp;<a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\"><span class=\"std std-ref\">The scoring parameter: defining model evaluation rules</span></a>.</p>\n",
    "</li>\n",
    "<li>\n",
    "<p><strong>Metric functions</strong>: The&nbsp;<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">metrics</span></code>&nbsp;module implements functions assessing prediction error for specific purposes. These metrics are detailed in sections on&nbsp;<a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\"><span class=\"std std-ref\">Classification metrics</span></a>,&nbsp;<a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#multilabel-ranking-metrics\"><span class=\"std std-ref\">Multilabel ranking metrics</span></a>,&nbsp;<a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\"><span class=\"std std-ref\">Regression metrics</span></a>&nbsp;and&nbsp;<a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#clustering-metrics\"><span class=\"std std-ref\">Clustering metrics</span></a>.</p>\n",
    "</li>\n",
    "</ul>\n",
    "<p>Finally,&nbsp;<a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators\"><span class=\"std std-ref\">Dummy estimators</span></a>&nbsp;are useful to get a baseline value of those metrics for random predictions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "hd = pd.read_csv(\"https://raw.githubusercontent.com/ineelhere/Machine-Learning-and-Data-Science/master/scikit-learn/heart-disease.csv\")\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 ways to evaluate sklearn models/estimators\n",
    "* Estimator `score()` method.\n",
    "* The `scoring` parameter.\n",
    "* Problem specific metric functions.\n",
    "<br><br>\n",
    "![](https://media.giphy.com/media/OnlFONDq5Z56g/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Evaluating Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get-set-go!\n",
    "\n",
    "# import the ensemble classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = hd.drop(\"target\", axis=1)\n",
    "y = hd[\"target\"]\n",
    "\n",
    "# split into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "\n",
    "# fit the model to the data = training the ML model\n",
    "clf = RandomForestClassifier() #isntantiate\n",
    "clf.fit(x_train, y_train) #fit\n",
    "\n",
    "# evaluate the above fitted RandomForestClassifier model = use the pattens the ML model has learnt above!\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `score() method` (already done above though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train,y_train) #Return the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test) #Return the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do the same, but now with regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5106393318965518"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the ensemble regressors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = hd.drop(\"target\", axis=1)\n",
    "y = hd[\"target\"]\n",
    "\n",
    "# split into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "\n",
    "# fit the model to the data = training the ML model\n",
    "model = RandomForestRegressor() #isntantiate\n",
    "model.fit(x_train, y_train) #fit\n",
    "\n",
    "# evaluate the above fitted RandomForestClassifier model = use the pattens the ML model has learnt above!\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924203269641995"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train,y_train) #Return the coefficient of determination R^2 of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5106393318965518"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test) #Return the coefficient of determination R^2 of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference?\n",
    "* for classification - `score()` - Return the `mean accuracy` on the given test data and labels.\n",
    "<br>\n",
    "<pre>\n",
    "In multi-label classification, this is the subset accuracy\n",
    "which is a harsh metric since you require for each sample that\n",
    "each label set be correctly predicted.\n",
    "</pre>\n",
    "* for regression - `score()` - Return the `coefficient of determination` R^2 of the prediction.\n",
    "<br>\n",
    "<pre>The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
    "sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
    "sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
    "The best possible score is 1.0 and it can be negative (because the\n",
    "model can be arbitrarily worse). A constant model that always\n",
    "predicts the expected value of y, disregarding the input features,\n",
    "would get a R^2 score of 0.0.\n",
    "</pre>\n",
    "\n",
    "<br>\n",
    "<br><strong>Yeah, you need to know the math!</strong><br>\n",
    "\n",
    "![](https://media.giphy.com/media/bupsZiBKn7vAk/giphy.gif)\n",
    "<br>\n",
    "In case you want to learn these statistical and mathematical concepts, this resource would be very helpful (available for free)<br><br>\n",
    "\n",
    "* MIT 18.650 Statistics for Applications, Fall 2016 - https://www.youtube.com/playlist?list=PLUl4u3cNGP60uVBMaoNERc6knT_MgPKS0\n",
    "* MIT OCW - https://ocw.mit.edu/courses/mathematics/18-650-statistics-for-applications-fall-2016/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first things first\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now set up a classification model (already done above though)\n",
    "\n",
    "# import the ensemble classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = hd.drop(\"target\", axis=1)\n",
    "y = hd[\"target\"]\n",
    "\n",
    "# split into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "\n",
    "# fit the model to the data = training the ML model\n",
    "clf = RandomForestClassifier() #isntantiate\n",
    "clf.fit(x_train, y_train) #fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.81967213, 0.78333333, 0.76666667])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signature:\n",
    "cross_val_score(\n",
    "    estimator,\n",
    "    X,\n",
    "    y=None,\n",
    "    groups=None,\n",
    "    scoring=None,\n",
    "    cv=None,\n",
    "    n_jobs=None,\n",
    "    verbose=0,\n",
    "    fit_params=None,\n",
    "    pre_dispatch='2*n_jobs',\n",
    "    error_score=nan,\n",
    ")\n",
    "##### Docstring: Evaluate a score by cross-validation\n",
    "\n",
    "Read more in the :ref:`User Guide <cross_validation>`.\n",
    "\n",
    "##### Parameters\n",
    "----------\n",
    "estimator : estimator object implementing 'fit'\n",
    "    The object to use to fit the data.\n",
    "\n",
    "X : array-like\n",
    "    The data to fit. Can be for example a list, or an array.\n",
    "\n",
    "y : array-like, optional, default: None\n",
    "    The target variable to try to predict in the case of\n",
    "    supervised learning.\n",
    "\n",
    "groups : array-like, with shape (n_samples,), optional\n",
    "    Group labels for the samples used while splitting the dataset into\n",
    "    train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
    "    instance (e.g., :class:`GroupKFold`).\n",
    "\n",
    "scoring : string, callable or None, optional, default: None\n",
    "    A string (see model evaluation documentation) or\n",
    "    a scorer callable object / function with signature\n",
    "    ``scorer(estimator, X, y)`` which should return only\n",
    "    a single value.\n",
    "\n",
    "    Similar to :func:`cross_validate`\n",
    "    but only a single metric is permitted.\n",
    "\n",
    "    If None, the estimator's default scorer (if available) is used.\n",
    "\n",
    "cv : int, cross-validation generator or an iterable, optional\n",
    "    Determines the cross-validation splitting strategy.\n",
    "    Possible inputs for cv are:\n",
    "\n",
    "    - None, to use the default 5-fold cross validation,\n",
    "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
    "    - :term:`CV splitter`,\n",
    "    - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
    "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
    "    other cases, :class:`KFold` is used.\n",
    "\n",
    "    Refer :ref:`User Guide <cross_validation>` for the various\n",
    "    cross-validation strategies that can be used here.\n",
    "\n",
    "    .. versionchanged:: 0.22\n",
    "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
    "\n",
    "n_jobs : int or None, optional (default=None)\n",
    "    The number of CPUs to use to do the computation.\n",
    "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "    for more details.\n",
    "\n",
    "verbose : integer, optional\n",
    "    The verbosity level.\n",
    "\n",
    "fit_params : dict, optional\n",
    "    Parameters to pass to the fit method of the estimator.\n",
    "\n",
    "pre_dispatch : int, or string, optional\n",
    "    Controls the number of jobs that get dispatched during parallel\n",
    "    execution. Reducing this number can be useful to avoid an\n",
    "    explosion of memory consumption when more jobs get dispatched\n",
    "    than CPUs can process. This parameter can be:\n",
    "\n",
    "        - None, in which case all the jobs are immediately\n",
    "          created and spawned. Use this for lightweight and\n",
    "          fast-running jobs, to avoid delays due to on-demand\n",
    "          spawning of the jobs\n",
    "\n",
    "        - An int, giving the exact number of total jobs that are\n",
    "          spawned\n",
    "\n",
    "        - A string, giving an expression as a function of n_jobs,\n",
    "          as in '2*n_jobs'\n",
    "\n",
    "error_score : 'raise' or numeric\n",
    "    Value to assign to the score if an error occurs in estimator fitting.\n",
    "    If set to 'raise', the error is raised.\n",
    "    If a numeric value is given, FitFailedWarning is raised. This parameter\n",
    "    does not affect the refit step, which will always raise the error.\n",
    "\n",
    "##### Returns\n",
    "-------\n",
    "scores : array of float, shape=(len(list(cv)),)\n",
    "    Array of scores of the estimator for each run of the cross validation.\n",
    "\n",
    "##### Examples\n",
    "--------\n",
    ">>> from sklearn import datasets, linear_model\n",
    ">>> from sklearn.model_selection import cross_val_score\n",
    ">>> diabetes = datasets.load_diabetes()\n",
    ">>> X = diabetes.data[:150]\n",
    ">>> y = diabetes.target[:150]\n",
    ">>> lasso = linear_model.Lasso()\n",
    ">>> print(cross_val_score(lasso, X, y, cv=3))\n",
    "[0.33150734 0.08022311 0.03531764]\n",
    "\n",
    "##### See Also\n",
    "-------\n",
    ":func:`sklearn.model_selection.cross_validate`:\n",
    "    To run cross-validation on multiple metrics and also to return\n",
    "    train scores, fit times and score times.\n",
    "\n",
    ":func:`sklearn.model_selection.cross_val_predict`:\n",
    "    Get predictions from each split of cross-validation for diagnostic\n",
    "    purposes.\n",
    "\n",
    ":func:`sklearn.metrics.make_scorer`:\n",
    "Make a scorer from a performance metric or loss function.\n",
    "\n",
    "Type:      function\n",
    "\n",
    "![](https://media.giphy.com/media/etGPvG1Pqj9ks/giphy.gif)\n",
    "\n",
    "* Cross Validation sklearn = https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "![](https://raw.githubusercontent.com/ineelhere/Machine-Learning-and-Data-Science/master/scikit-learn/scoring%20model%20via%20cross-validation.png)\n",
    "Now see the code below.<br>\n",
    "I can see that smile on your face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83606557, 0.8852459 , 0.7704918 , 0.8       , 0.8       ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cv=5 means 5 fold splits (5 is default, you can change it as per requirement)\n",
    "* So the above code made 5 different splits and gave 5 different scores.\n",
    "* Now you can choose the ideal one - you can also take the average of the 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8248087431693989)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#single train and test split score\n",
    "clf_single_score = clf.score(x_test, y_test)\n",
    "\n",
    "#mean or average of 5 fold cross validation score\n",
    "clf_cross_val = np.mean(cross_val_score(clf, x, y, cv=5))\n",
    "\n",
    "#compare\n",
    "clf_single_score, clf_cross_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So, we see that the cross validation score is a little lower than the single score.\n",
    "* But from the accuracy point of view, cross validation score is more accurate \n",
    "\n",
    "Now, the question is - Why is cross validation more accurate?\n",
    "\n",
    "Answer - \n",
    "* In cross_val_score() method, the scoring parameter is set to NONE by default.\n",
    "* If you notice above, the cross_val_score() method's scoring parameter says - \" If None, the estimator's default scorer (if available) is used.\"\n",
    "* This refers to the accuracy!\n",
    "\n",
    "![](https://media.giphy.com/media/PqcIFm93VxA8o/giphy.gif)\n",
    "\n",
    "Let's move on to the next strategy to evaluate a classification model <hr>\n",
    "\n",
    "### Classification Model Evaluation Metrics functions\n",
    "* Accuracy\n",
    "* Area under ROC Curve\n",
    "* Confusion Matrix\n",
    "* Classification report\n",
    "\n",
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = hd.drop(\"target\", axis=1)\n",
    "y = hd[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier() #isntantiate\n",
    "\n",
    "cvs = cross_val_score(clf,x,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Cross Validated Accuracy :  82.48 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Heart Disease Classifier Cross Validated Accuracy : {np.mean(cvs) * 100 : .2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did this earlier! Isn't it? <br>\n",
    "So, do not ever get overwhelmed with the new \"terms\" <br>\n",
    "The answer often lies in the question itself :)\n",
    "\n",
    "##### Remember - Higher accuracy `does not always` mean it is the best! <hr>\n",
    "\n",
    "**Area under the receiver operating characteristic curve**\n",
    "* Area under curve (AUC)\n",
    "* ROC curve - comparison of a model's true positive rate (tpr) v/s a model's false positive rate (fpr)\n",
    "\n",
    "True positive means `model predicts 1 when truth is 1` <br>\n",
    "False positive means `model predicts 1 when truth is 0` <br>\n",
    "Truth negative means `model predicts 0 when truth is 0` <br>\n",
    "False negative means `model predicts 0 when truth is 1`\n",
    "\n",
    "An interesting article - https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-b67b6d83c479>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-b67b6d83c479>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ** AUC/ROC **\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python38132bit93aab49dff954651a4c1e4402da878fd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
