{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Machine Learning Models\n",
    "\n",
    "![](https://i.pinimg.com/originals/76/b3/9e/76b39e4a15127c0ba8320997f18b5810.gif)\n",
    "\n",
    "\n",
    "The first predictions we make with a model are generally referred to as **baseline predictions**. <br>The same goes with the first evaluation metrics we get. These are generally referred to as **baseline metrics**. <br>\n",
    "\n",
    "`Let's do the first things first!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "hd = pd.read_csv(\"https://raw.githubusercontent.com/ineelhere/Machine-Learning-and-Data-Science/master/scikit-learn/heart-disease.csv\")\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get-set-go!\n",
    "\n",
    "# import the ensemble classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = hd.drop(\"target\", axis=1)\n",
    "y = hd[\"target\"]\n",
    "\n",
    "# split into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "\n",
    "# fit the model to the data = training the ML model\n",
    "clf = RandomForestClassifier() #isntantiate\n",
    "clf.fit(x_train, y_train) #fit\n",
    "\n",
    "# evaluate the above fitted RandomForestClassifier model = use the pattens the ML model has learnt above!\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next goal is to **improve upon these baseline metrics**. <br>\n",
    "\n",
    "Two of the main methods to improve baseline metrics are from a data perspective and a model perspective.<br>\n",
    "\n",
    "**From a data perspective :** <br>\n",
    "\n",
    "* `Could we collect more data?`<br> In machine learning, more data is generally better, as it gives a model more opportunities to learn patterns.<br>\n",
    "* `Could we improve our data?`<br> This could mean filling in misisng values or finding a better encoding (turning things into numbers) strategy.\n",
    "\n",
    "**From a model perspective :** \n",
    "<br>\n",
    "\n",
    "* `Is there a better model we could use?` <br>If we've started out with a simple model, could we use a more complex one? (we saw an example of this when looking at the Scikit-Learn machine learning map, ensemble methods are generally considered more complex models)\n",
    "* `Could we improve the current model?` <br>If the model we're using performs well straight out of the box, can the hyperparameters be tuned to make it even better?\n",
    "<br><br>**Note:** `Patterns in data are also often referred to as data parameters`. <br>The difference between parameters and hyperparameters is-<br>\n",
    "* a machine learning model seeks to find parameters in data on its own, where as, \n",
    "* hyperparameters are settings on a model which a user (we) can adjust.\n",
    "\n",
    "<br>Since we have two existing datasets, we'll come at exploration from a model perspective.<br>\n",
    "\n",
    "More specifically, we'll look at how we could improve our RandomForestClassifier and RandomForestRegressor models through **hyperparameter tuning**.\n",
    "\n",
    "**`Now, What are hyperparameters?`**\n",
    "<br>\n",
    "When we instantiate a model like above, we're using the *default hyperparameters.*<br>\n",
    "These get printed out when we call the model instance and `get_params()`. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go here https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html <br>\n",
    "Everything listed as \"Parameters\" are actually Hyperparameters in this case.\n",
    "\n",
    "**Let me make this a bit simpler** <br>\n",
    "\n",
    "See this\n",
    "![](https://media1.tenor.com/images/1da9cb530544c70110a1ce2dd662db17/tenor.gif?itemid=8578128)\n",
    "<br>\n",
    "Mr. Bean had to adjust his face/expressions unless it matched with his image on the passport.\n",
    "<br>Simply put, he had to make changes to a few parameters unless the motive was achieved!<br>\n",
    "That's exactly what we do in ML, to improve a model - tune the `(hyper)parameters`\n",
    "\n",
    "<br>(I know you are smiling, but this helps - right?)\n",
    "<br>So now, we will **Tune the Hyperparameters**\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Tune the Hyperparameters\n",
    "\n",
    "![](https://github.com/ineelhere/Machine-Learning-and-Data-Science/blob/master/scikit-learn/sklearn-train-valid-test-annotated.png?raw=true)\n",
    "\n",
    "<br>See the image above?\n",
    "* Hyperparameter tuning `introduces a thrid set, a validation set`.\n",
    "* Now the process becomes, `train a model on the training data`, <br>(try to) `improve its hyperparameters on the validation set` <br>and `evaluate it on the test set`.\n",
    "* If our starting dataset contained 100 different patient records labels indicating who had heart disease and who didn't and we wanted to build a machine learning model to predict who had heart disease and who didn't, it might look like the above image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so let's see the base parameters again\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will adjust the -**\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`\n",
    "\n",
    "We'll use the same code as before, except this time we'll create a training, validation and test split.\n",
    "\n",
    "With the training set containing 70% of the data and the validation and test sets each containing 15%.\n",
    "\n",
    "Let's get some baseline results, then we'll tune the model.\n",
    "\n",
    "And since we're going to be evaluating a few models, let's make an evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2), \n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 45, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the train evaluation and test splits\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#shuffle the data - using pandas\n",
    "hds = hd.sample(frac=1)\n",
    "\n",
    "#split into x and y\n",
    "x = hds.drop(\"target\", axis=1)\n",
    "y = hds.target\n",
    "\n",
    "#split the data into train, validation and test sets\n",
    "train_split = round(0.7*len(hds)) #0.7 indicates 70% of the data\n",
    "valid_split = round(train_split + 0.15 * len(hds)) # 70% + 15% of the data\n",
    "x_train, y_train = x[:train_split], y[:train_split]\n",
    "x_valid, y_valid = x[train_split : valid_split], y[train_split : valid_split]\n",
    "x_test, y_test = x[valid_split:], y[:valid_split]\n",
    "\n",
    "#lets see what just happened\n",
    "len(x_train), len(x_valid), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets work on the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.81\n",
      "Recall: 0.88\n",
      "F1 score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.81, 'recall': 0.88, 'f1': 0.85}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model (as usual)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#make baseline predictions on the validation data\n",
    "y_preds = clf.predict(x_valid)\n",
    "\n",
    "#evaluate the classifier on the validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "\n",
    "#moment of truth!\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Ok, now let us make the changes using different hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 score: 0.84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions with different hyperparameters\n",
    "y_preds_2 = clf_2.predict(x_valid)\n",
    "\n",
    "# Evaluate the 2nd classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice the change in results?**\n",
    "* Acc is same\n",
    "* Precision inreased slightly\n",
    "* Recall score decreased\n",
    "* F1 score decreased\n",
    "<br><br>So, it's a mixture of good and bad. Let us try and see if we can improve...\n",
    "<br><br><br><br>\n",
    "Making changes manually to the hyperparameters will make the task a time-consuming one. We dont want that!<br>\n",
    "Sklearn has got us covered here. We will use `RandomizedSearchCV` for this purpose. <br>\n",
    "Read here - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "\n",
    "## Tune hyperparameters with `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python38132bit93aab49dff954651a4c1e4402da878fd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
